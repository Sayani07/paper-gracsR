---
title: "Hand picking similar behaving group of customers to check clustering results"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, echo = FALSE, message=FALSE, warning=FALSE)
library(readr)
library(tidyverse)
library(gravitas)
library(tsibble)
library(parallel)
library(magrittr)
library(GGally)
library(knitr)
library(patchwork)
library(caret)
```


```{r read-data}
data <- read_rds("../../../data/elec_nogap_2013_100.rds")
```

```{r hand-pick}
quantile_prob_val = seq(0.1, 0.9, 0.1)

# data_pick <- data %>% 
#   filter(customer_id %in% 
#                    c(10538785, 8530300, 8717912, 8171227, 10108102, 10767756, 10895401, 10704368, 9397229, 8281474))

data_pick_onepeak <- 
  data %>% 
  filter(customer_id %in% c(8485375,10690820,10859082,8486921, 10208124,8198401))%>% mutate(design = 1)

data_pick_threepeak <- 
  data %>% 
  filter(customer_id %in% c(11013154, 10046512, 8637773, 8952846, 8196501, 8627007))%>% mutate(design = 3)

data_pick_twopeak <- 
  data %>% 
  filter(customer_id %in% c(8181071, 8955520, 8640839, 10469265, 10538785, 10895401))%>% mutate(design = 2)

data_pick <- bind_rows(data_pick_onepeak, data_pick_twopeak, data_pick_threepeak)

elec_harmony_all <- read_rds("../../../data/elec_harmony-100-nogap-new.rds")%>%
  filter(customer_id %in% data_pick$customer_id)

elec_harmony_hod <- elec_harmony_all %>% filter(x_variable=="hour_day") %>% 
  mutate(wpd = round(wpd, 2))

group2_data <- data_pick %>% 
  create_gran("hour_day") %>% 
  as_tibble() %>% 
  group_by(design, hour_day, customer_id) %>% 
  summarise(median_kwh = median(general_supply_kwh)) 

# 
# group2_data%>% 
#   ungroup() %>% 
#   filter(design==1) %>% 
#   #filter(customer_id %in% c(8148781, 10703878)) %>% 
#   ggplot(aes(x = as.integer(hour_day), y = median_kwh)) +
#   geom_line(size = 0.5) +
#   facet_wrap(~customer_id, scales = "free_y") + theme_minimal()+ theme(strip.text.y = element_text(size = 5))
# 
# 
# group2_data%>% 
#   ungroup() %>% 
#   filter(design==2) %>% 
#   #filter(customer_id %in% c(8148781, 10703878)) %>% 
#   ggplot(aes(x = as.integer(hour_day), y = median_kwh)) +
#   geom_line(size = 0.5) +
#   facet_wrap(~customer_id, scales = "free_y") + theme_minimal()+ theme(strip.text.y = element_text(size = 5))
```


```{r characterize, fig.cap= "Median (black) and quartile deviation (blue region) of hourly demand drawn for few customers showing similar behaviors. Roughly speaking, Design 1 has one evening peak, Design 2 has two peaks and Design 3 has three peaks in a day. Each of design 1, 2 and 3 have six similar behaving customers resulting to 18 time series. We want our clustering results to group each of the designs together."}
quantile_prob_val = c(0.25, 0.5, 0.75)
  
sm_hod <- gravitas::create_gran(data_pick, "hour_day")


sm_hod_list <- sm_hod %>% 
  as_tibble() %>% 
  select(design, customer_id, hour_day, general_supply_kwh) %>% 
  pivot_wider(names_from = hour_day,
              values_from = general_supply_kwh)

# groups_ref <- unique(data_pick$design) %>% as_tibble %>% 
#               mutate(customer_serial_id = sm_hod_list$customer_id) 

# sm_hod_list_cat <-  sm_hod_list %>% left_join(groups_ref, by = c("customer_id" = "customer_serial_id")) %>% select(group, everything())
  
ncol_sm <- seq_len(ncol(sm_hod_list[-c(1, 2)]))
nrow_sm <- 1:18


sm_hod_quantiles_cat <- map(nrow_sm, function(x){
  map(ncol_sm, function(y){
   cell <- sm_hod_list%>% 
     dplyr::filter(customer_id == customer_id[x]) %>% 
     select(-c(1, 2)) %>% 
     extract(y) %>% 
     unlist()
   quantile(cell, prob = quantile_prob_val)
})  %>% bind_rows(.id = "categories_serial_id")
}) %>% bind_rows(.id = "customer_serial_id") 


ref_cat <- names(sm_hod_list)[-c(1, 2)] %>% as_tibble() %>% set_names("category") %>%  
  mutate(categories_serial_id = row_number())


ref_cust <- sm_hod_list$customer_id %>% as_tibble()%>% set_names("customer_id")  %>% 
    mutate(customer_serial_id = row_number())
  
sm_quantiles_ref <- sm_hod_quantiles_cat %>% 
  mutate(customer_serial_id = as.integer(customer_serial_id),
         categories_serial_id = as.integer(categories_serial_id)) %>% 
  left_join(ref_cat, by = "categories_serial_id") %>% 
  left_join(ref_cust, by = "customer_serial_id") %>% 
  select(customer_serial_id, categories_serial_id, category, customer_id, everything())

data_heatmap <- sm_quantiles_ref %>% 
 left_join(data_pick %>% distinct(customer_id, design))
  

# 
# %>% 
#   left_join(categories_ref_cat) %>% 
#   rename("category" = "value") %>% 
#   select(-categories_serial_id) %>% 
#   mutate(category = as.numeric(category))



data_heatmap %>% 
  ggplot(aes(x = as.integer(category))) + 
  geom_ribbon(aes(ymin = `25%`, 
                  ymax = `75%`), fill = "lightblue") +
  #geom_line(aes(y = `50%`), size = 0.7) +
  geom_smooth(aes(y = `50%`), size = 0.7) +
  facet_wrap(design~customer_id, 
             scales = "free_y", 
             labeller = "label_value",
             ncol = 6) +
  theme_bw() +
    theme(strip.text = element_text(size = 10, margin = margin(b = 0, t = 0))) + xlab("hour-of-day") + ylab("demand (in Kwh)")
```



```{r plot-hand-pick, fig.cap= "Median hourly demand drawn for few customers showing similar median behavior. Roughly speaking, Design 1 has one evening peak, Design 2 has two peaks and Design 3 has three peaks in a day. Each of design 1, 2 and 3 have six similar behaving customers resulting to 18 time series. We want our clustering results to group each of the designs together.", eval = FALSE}
group2_data%>% 
  ungroup() %>% 
  left_join(elec_harmony_hod %>% select(customer_id, wpd)) %>% 
  #filter(design==3) %>% 
  #filter(customer_id %in% c(8148781, 10703878)) %>% 
  ggplot(aes(x = as.integer(hour_day), y = median_kwh)) +
  geom_line(size = 0.5) +
  #ggtitle(paste("wpd:", elec_harmony_hod$wpd)) +
  facet_wrap(design~customer_id, scales = "free_y", ncol = 6, labeller = "label_value") + theme_minimal()+ theme(strip.text.y = element_text(size = 5)) 
```




```{r allplot, message=FALSE, warning=FALSE, echo = FALSE}

##----harmony-all
elec <- read_rds("../../../data/elec_nogap_2013_100.rds") %>% filter(customer_id %in% data_pick$customer_id)

elec_split = elec %>% group_split(customer_id)
harmonies <- read_rds("../../../../paper-hakear/paper/data/harmonies.rds")

harmonies_acro <- harmonies %>% mutate(facet_variable=NA, facet_levels=NA) %>% distinct()

elec_select_harmony = parallel::mclapply(1:18, function(x){

  data_id <-  elec_split %>% magrittr::extract2(x) %>%
    as_tsibble(index = reading_datetime)


  k = hakear::select_harmonies(data_id,
                           harmony_tbl = harmonies_acro,
                           response = general_supply_kwh,
                           nperm = 200,
                           nsamp = 200
  ) %>% mutate(customer_id = unique(data_id$customer_id))
    #write_rds(k, paste("data/elec_harmony-100-nogap.rds"))
}, mc.cores = parallel::detectCores() - 1, mc.preschedule = FALSE, mc.set.seed = FALSE)
#toc()
elec_harmny <- elec_select_harmony %>% bind_rows()
 write_rds(elec_harmny, paste("../../../data/elec_harmony-100-nogap-new-rerun.rds"))

f = read_rds("../../../data/elec_harmony-100-nogap-new.rds")

select_split <- str_split(elec_harmony_all$select_harmony, " ", simplify = TRUE)[,2]

elec_sig_split <- elec_harmony_all %>%
  mutate(facet_variable = case_when(
    facet_variable == "hour_day" ~ "hod" ,
    facet_variable == "day_month" ~ "dom" ,
    facet_variable == "day_week" ~ "dow" ,
    facet_variable == "week_month" ~ "wom" ,
    facet_variable == "wknd_wday" ~ "wdwnd"
  )) %>% 
  mutate(x_variable = case_when(
    x_variable == "hour_day" ~ "hod" ,
    x_variable == "day_month" ~ "dom" ,
    x_variable == "day_week" ~ "dow" ,
    x_variable == "week_month" ~ "wom" ,
    x_variable == "wknd_wday" ~ "wdwnd"
  )) %>% 
  bind_cols(select_split = select_split) %>% 
  mutate(significant = case_when(
    select_split == "***" ~ "highest",
    select_split == "**" ~ "high",
    select_split == "*" ~ "medium",
    select_split == "" ~ "low"
  )) %>%mutate(comb = x_variable) 


elec_sig_split$significant <- 
  factor(elec_sig_split$significant, levels = c("highest", "high", "medium", "low")) 
  

data_comb_filter = elec_sig_split %>% 
mutate(low_proxy = if_else(significant=="low", 0, 1))%>% 
select(comb, customer_id, low_proxy) %>% 
pivot_wider(names_from = customer_id, values_from = low_proxy) %>%
mutate(score = rowMeans(across(-1))) %>% 
filter(score >0.3)


data_sig_filter = elec_sig_split %>% 
filter(comb %in% data_comb_filter$comb)

data_clust = data_sig_filter %>% 
select(comb, customer_id, wpd) %>% 
pivot_wider(names_from = comb, values_from = wpd) 
```

```{r hc-plot, fig.cap="Dendogram from clustering 18 time series into three clusters."}
hc = stats::hclust(dist(data_clust[-1]),method="complete")
#plot(hc)
plot(hc, cex = 0.6)
rect.hclust(hc, k = 3, border = 2:10)
```


```{r conf-matrix, fig.cap="The confusion matrix showing how well the clustering algorithm worked."}
groups <- cutree(hc, k=3) %>% 
  as_tibble() %>% 
mutate(customer_id = data_clust$customer_id)

elec_pred_wo_scaled <- elec_harmony_all %>% 
  filter(x_variable %in% c("hour_day", "day_month")) %>% 
  left_join(data_pick %>% as_tibble() %>% select(customer_id, design)%>% unique) %>% select(-facet_variable, -facet_levels, -x_levels, -select_harmony) %>% 
  pivot_wider(names_from = x_variable, values_from = wpd) %>% 
  left_join(groups) %>% 
  rename("pred_design" = "value") %>% 
  arrange(day_month) %>% 
  select(customer_id, design, pred_design, everything()) %>%
  mutate(day_month = round(day_month, 1),
         hour_day = round(hour_day, 1)) 



elec_pred_wo_scaled$design = as.factor(elec_pred_wo_scaled$design)
elec_pred_wo_scaled$pred_design = as.factor(elec_pred_wo_scaled$pred_design)
xtab <- confusionMatrix(elec_pred_wo_scaled$pred_design, elec_pred_wo_scaled$design)
xtab$table
```

```{r tab-cluster}
# 
#  fig.cap="The customers are arranged in ascending order of wpd for dom and it can be seen that the predicted designs are exactly sorted in that order."
elec_pred_wo_scaled%>% 
  kable(caption = "Actual and predicted allocation of designs to customers" )

```

\newpage

##----cluster-characterization

```{r}
data = data_clust %>% 
left_join(groups)%>% 
             rename ("group" = "value") %>% 
             ungroup() %>% 
             select(group, customer_id, everything()) %>% 
             pivot_longer(-c(1,2), names_to = "comb", values_to = "wpd")

data_pcp <- data %>% pivot_wider(
              names_from = comb, 
              values_from = wpd) %>% 
  mutate(group = as.character(group)) 
```


```{r ggpairs-plot, fig.cap="Pairs plot show that dom is the variable that is responsible for this clustering. The green colored cluster correspond to lowest value of dom, the orange colored and blue colored one correspond to middle range and high range of dom."}
# ggpairs_nocolor <- ggpairs(data_pcp, columns = 3:7)
# ggpairs_nocolor

groupge2 <- data %>% 
  group_by(group) %>% 
  summarise(n = length(unique(customer_id))) %>% 
  filter(n>2)


data_pcp_ge2 <- data_pcp %>% filter(group %in% groupge2$group)

# ggpairs_nocolor <- ggpairs(data_pcp_ge2, columns = 3:7)


ggpairs_nocolor <- ggscatmat(data_pcp_ge2, columns=3:4) +
  scale_colour_brewer(palette="Set2") + theme(legend.position = "bottom")

ggpairs_color <- ggscatmat(data_pcp_ge2, columns=3:4, color = "group") +
  scale_colour_brewer(palette="Set2") + theme(legend.position = "bottom")

ggpairs_nocolor + ggpairs_color
```



```{r pred-actual-design, fig.cap="First facet label indicate actual design, second denote predicted design, third denote customer_id."}
group_data_orig <- group2_data %>% left_join(elec_pred_wo_scaled %>% select(customer_id,pred_design))


# group_data_orig%>% 
#   ungroup() %>% 
#   filter(group==1) %>% 
#   #filter(customer_id %in% c(8148781, 10703878)) %>% 
#   ggplot(aes(x = as.integer(hour_day), y = median_kwh)) +
#   geom_line(size = 0.5) +
#   facet_wrap(~customer_id, scales = "free_y",labeller = "label_value", ncol = 1) + theme_minimal()+ theme(strip.text.y = element_text(size = 5))
# 
# 
# group_data_orig%>% 
#   ungroup() %>% 
#   filter(group==2) %>% 
#   #filter(customer_id %in% c(8148781, 10703878)) %>% 
#   ggplot(aes(x = as.integer(hour_day), y = median_kwh)) +
#   geom_line(size = 0.5) +
#   facet_wrap(~customer_id, scales = "free_y",labeller = "label_value", ncol = 1) + theme_minimal()+ theme(strip.text.y = element_text(size = 5))


group_data_orig%>% 
  ungroup() %>% 
  rename("pred" = "pred_design", "cust" = "customer_id") %>% 
  #filter(group==3) %>% 
  #filter(customer_id %in% c(8148781, 10703878)) %>% 
  ggplot(aes(x = as.integer(hour_day), y = median_kwh)) +
  geom_line(size = 0.5) +
  facet_wrap(design~pred~cust, scales = "free_y",labeller = "label_context") + theme_minimal()+ theme(strip.text.y = element_text(size = 5)) + 
       theme(strip.text.x = element_text(size = 6, margin = margin(b = 0, t = 0)))+ xlab("hod")
```

```{r dom-pred, fig.cap="(Top) free y scale, (bottom) y scales same across facets seemingly implies that clustering is ordered by sorting the median demand."}
group2_data <- data_pick %>% 
  create_gran("day_month") %>% 
  as_tibble() %>% 
  #mutate(general_supply_kwh = scale(general_supply_kwh)) %>% 
  group_by(design, day_month, customer_id) %>% 
  summarise(median_kwh = median(general_supply_kwh)) 

group_data_orig <- group2_data %>% left_join(elec_pred_wo_scaled %>% select(customer_id,pred_design))


group_data_orig %>% 
  ungroup() %>% 
  rename("pred" = "pred_design", "cust" = "customer_id") %>% 
  #filter(group==3) %>% 
  #filter(customer_id %in% c(8148781, 10703878)) %>% 
  ggplot(aes(x = as.integer(day_month), y = median_kwh)) +
  geom_line(size = 0.5) +
  facet_wrap(pred~cust,
             labeller = "label_context",
             scales = "free_y") + 
  theme_minimal()+ theme(strip.text.y = element_text(size = 5)) + scale_y_log10() + scale_x_continuous(breaks=seq(1, 31, 7), minor_breaks = seq(1, 31, 7))+ 
       theme(strip.text.x = element_text(size = 6, margin = margin(b = 0, t = 0)))+ xlab("dom")

### new quantile scale
quantile_prob_val = c(0.25, 0.5, 0.75)
  
sm_hod <- gravitas::create_gran(data_pick, "day_month")


sm_hod_list <- sm_hod %>% 
  as_tibble() %>% 
  select(design, customer_id, day_month, general_supply_kwh) %>% 
  pivot_wider(names_from = day_month,
              values_from = general_supply_kwh)

# groups_ref <- unique(data_pick$design) %>% as_tibble %>% 
#               mutate(customer_serial_id = sm_hod_list$customer_id) 

# sm_hod_list_cat <-  sm_hod_list %>% left_join(groups_ref, by = c("customer_id" = "customer_serial_id")) %>% select(group, everything())
  
ncol_sm <- seq_len(ncol(sm_hod_list[-c(1, 2)]))
nrow_sm <- 1:18


sm_hod_quantiles_cat <- map(nrow_sm, function(x){
  map(ncol_sm, function(y){
   cell <- sm_hod_list%>% 
     dplyr::filter(customer_id == customer_id[x]) %>% 
     select(-c(1, 2)) %>% 
     extract(y) %>% 
     unlist()
   quantile(cell, prob = quantile_prob_val)
})  %>% bind_rows(.id = "categories_serial_id")
}) %>% bind_rows(.id = "customer_serial_id") 


ref_cat <- names(sm_hod_list)[-c(1, 2)] %>% as_tibble() %>% set_names("category") %>%  
  mutate(categories_serial_id = row_number())


ref_cust <- sm_hod_list$customer_id %>% as_tibble()%>% set_names("customer_id")  %>% 
    mutate(customer_serial_id = row_number())
  
sm_quantiles_ref <- sm_hod_quantiles_cat %>% 
  mutate(customer_serial_id = as.integer(customer_serial_id),
         categories_serial_id = as.integer(categories_serial_id)) %>% 
  left_join(ref_cat, by = "categories_serial_id") %>% 
  left_join(ref_cust, by = "customer_serial_id") %>% 
  select(customer_serial_id, categories_serial_id, category, customer_id, everything())

data_heatmap <- sm_quantiles_ref %>% 
 left_join(data_pick %>% distinct(customer_id, design))
  

# 
# %>% 
#   left_join(categories_ref_cat) %>% 
#   rename("category" = "value") %>% 
#   select(-categories_serial_id) %>% 
#   mutate(category = as.numeric(category))



data_heatmap %>% 
  ggplot(aes(x = as.integer(category))) + 
  geom_ribbon(aes(ymin = `25%`, 
                  ymax = `75%`), fill = "lightblue") +
  #geom_line(aes(y = `50%`), size = 0.7) +
  facet_wrap(design~customer_id, 
             scales = "free_y", 
             labeller = "label_value",
             ncol = 6) +
  theme_bw() +
    theme(strip.text = element_text(size = 10, margin = margin(b = 0, t = 0))) + xlab("hour-of-day") + ylab("demand (in Kwh)") +
  geom_smooth(aes(y = `50%`)) +
   geom_smooth(aes(y = `25%`), se = FALSE) +
   geom_smooth(aes(y = `75%`), se = FALSE) +
  scale_y_log10()




### all same scale 
group_data_orig$customer_id <-factor(group_data_orig$customer_id, levels = elec_pred_wo_scaled$customer_id)

group_data_orig %>% 
  ungroup() %>% 
  rename("pred" = "pred_design", "cust" = "customer_id") %>% 
  #filter(group==3) %>% 
  #filter(customer_id %in% c(8148781, 10703878)) %>% 
  ggplot(aes(x = as.integer(day_month), y = median_kwh)) +
  geom_line(size = 0.5) +
  facet_wrap(pred~cust,
             labeller = "label_context") + 
  theme_minimal()+ theme(strip.text.y = element_text(size = 5)) + scale_y_log10() + scale_x_continuous(breaks=seq(1, 31, 7), minor_breaks = seq(1, 31, 7))+ 
       theme(strip.text.x = element_text(size = 6, margin = margin(b = 0, t = 0))) + xlab("dom")
```

```{r, eval = FALSE}
data_clust = data_sig_filter %>% 
select(comb, customer_id, wpd) %>% 
pivot_wider(names_from = comb, values_from = wpd) %>% 
  mutate(hod = scale(hod),
         dom = scale(dom))

hc = stats::hclust(dist(data_clust[-1], method = "manhattan"),method="complete")
#plot(hc)
plot(hc, cex = 0.6)
rect.hclust(hc, k = 3, border = 2:10)


groups_scaled <- cutree(hc, k=3) %>% 
  as_tibble() %>% 
mutate(customer_id = data_clust$customer_id) %>% rename("pred_design_scale" = "value")

elec_harmony_all %>% 
  filter(x_variable %in% c("hour_day", "day_month")) %>% 
  left_join(data_pick %>% as_tibble() %>% select(customer_id, design)%>% unique) %>% select(-facet_variable, -facet_levels, -x_levels, -select_harmony) %>% 
  pivot_wider(names_from = x_variable, values_from = wpd) %>% 
  mutate(hod_scaled =  round(scale(hour_day), 1), 
         dom_scaled = round(scale(day_month),1)) %>% 
  left_join(groups_scaled)  %>%
  mutate(day_month = round(day_month, 1),
         hour_day = round(hour_day, 1)) %>% 
  left_join(elec_pred_wo_scaled %>% select(customer_id, pred_design), by = "customer_id") %>% 
  arrange(design) %>% 
  select(customer_id, design, pred_design_scale, pred_design, everything()) %>% 
  kable()

##----cluster-characterization

data = data_clust %>% 
left_join(groups)%>% 
             rename ("group" = "value") %>% 
             ungroup() %>% 
             select(group, customer_id, everything()) %>% 
             pivot_longer(-c(1,2), names_to = "comb", values_to = "wpd")

data_pcp <- data %>% pivot_wider(
              names_from = comb, 
              values_from = wpd) %>% 
  mutate(group = as.character(group)) 
```


```{r, eval = FALSE}
# ggpairs_nocolor <- ggpairs(data_pcp, columns = 3:7)
# ggpairs_nocolor

groupge2 <- data %>% 
  group_by(group) %>% 
  summarise(n = length(unique(customer_id))) %>% 
  filter(n>2)


data_pcp_ge2 <- data_pcp %>% filter(group %in% groupge2$group)

# ggpairs_nocolor <- ggpairs(data_pcp_ge2, columns = 3:7)


ggpairs_nocolor <- ggscatmat(data_pcp_ge2, columns=3:4) +
  scale_colour_brewer(palette="Set2") + theme(legend.position = "bottom")

ggpairs_color <- ggscatmat(data_pcp_ge2, columns=3:4, color = "group") +
  scale_colour_brewer(palette="Set2") + theme(legend.position = "bottom")

ggpairs_nocolor + ggpairs_color
```


# Algorithm discussed today

- take significant granularities
- consider sum of JS distances between each categories of each cyclic granularity

